{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrq_data = {\n",
    "    x: pl.read_csv(\n",
    "        f'../data/{x}_qrq.csv',\n",
    "        null_values = 'NA'\n",
    "    )\n",
    "    for x in ['raw', 'clean']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML model is meant to capture the following relationship:\n",
    "\n",
    "$\n",
    "flag = f(d2m_{i,g}, d2lm_{i,g}, d2pym_{i,g}, n_g, l_i, y2e_i, tps_i)\n",
    "$\n",
    "\n",
    "where,\n",
    "\n",
    "- $flag = \\begin{cases} 1 &\\text{if individual was dropped from the final sample} \\\\ 0 &\\text{if individual is present in the final sample} \\end{cases}$\n",
    "\n",
    "- $d2m = s_n - s_i$, and $s_n$ is te average group $g$ score and $s_i$ is the score obtained by the individual\n",
    "\n",
    "- $d2lm = \\dfrac{s_l - s_i}{d2m}$, and $s_l$ is the average longitudinal group $g$ score\n",
    "\n",
    "- $d2pym = \\dfrac{s_py - s_i}{d2m}$, and $s_py$ is the average group $g$ score for $t-1$\n",
    "\n",
    "- $n$ is the size of group $g$\n",
    "\n",
    "- $y2e$ is the number of years between the individual's answers and the ROLI edition\n",
    "\n",
    "- $tps$ ... TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrq_data_raw_processed = (\n",
    "    qrq_data['raw']\n",
    "    .with_columns(\n",
    "        pl.col('roli').mean().over('country').alias('avg_country_score'),\n",
    "        pl.col('roli').std().over('country').alias('std_country_score')\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.len().over('country', 'edition').alias('pool_size'),\n",
    "\n",
    "        pl.col('roli')\n",
    "        .filter(pl.col('longitudinal') == 1)\n",
    "        .mean()\n",
    "        .over('country')\n",
    "        .alias('avg_country_longitudinal_score'),\n",
    "\n",
    "        (pl.col('unid').is_in(qrq_data['clean']['unid']).not_())\n",
    "        .cast(pl.Int8)\n",
    "        .alias('dropped'),\n",
    "\n",
    "        (pl.col('roli') - pl.col('avg_country_score'))\n",
    "        .alias('distance2mean'),\n",
    "\n",
    "        (pl.col('year') - pl.col('edition'))\n",
    "        .alias('distance2edition')\n",
    "\n",
    "        # N flags in subfactors (% of total flags) * distance2mean\n",
    "        # N Flags in TPS * Distance to prev year mean\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col('distance2mean') / pl.col('std_country_score')).alias('distance2mean_nstd')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\n",
    "    qrq_data_raw_processed\n",
    "    .select(['distance2mean'])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qrq-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
